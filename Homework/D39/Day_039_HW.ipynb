{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請閱讀相關文獻，並回答下列問題\n",
    "\n",
    "[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n",
    "[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n",
    "\n",
    "1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
    "2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
    "\n",
    "Feature selection ==> 特征选择\n",
    "\n",
    "Lasso方法下解出的参数常常具有稀疏的特征，即很多特征对应的参数会为零，\n",
    "这就使得特征选择成为可能：我们可以训练一个Lasso模型，然后将系数为零的特征去除。\n",
    "\n",
    "### refer : <a href='http://sofasofa.io/forum_main_post.php?postid=1001156'>为什么LASSO可以做特征选择，而Ridge却不行？</a>\n",
    "LASSO是L1正则，Ridge是L2正则。而L1正则与L2正则的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，\n",
    "而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性，\n",
    "例如图中的相交点就有w1=0，而更高维的时候除了角点以外，还有很多边的轮廓也是既有很大的概率成为第一次相交的地方，又会产生稀疏性。\n",
    "\n",
    "相比之下，L2正则就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了。\n",
    "这就从直观上来解释了为什么L1正则，而L2正则不行的原因了。\n",
    "\n",
    "因此，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。\n",
    "Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。\n",
    "\n",
    "<img src='https://img-blog.csdn.net/20150315231654483'>\n",
    "\n",
    "上面是示意图。左边是LASSO，右边是Ridge。\n",
    "\n",
    "LASSO的目标函数是非光滑的。我们知道对于非光滑的优化问题，\n",
    "它的最优解要么是在导数为0处，要么就是在不可导的地方，也就是各个角上。对于多维的LASSO，所谓的“角”，就是那些很多特征的系数为0的地方。\n",
    "\n",
    "所以LASSO会给出一个稀疏解，能有特征选择的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n",
    "\n",
    "当设计矩阵XX存在**多重共线性**的时候（数学上称为病态矩阵），\n",
    "最小二乘法求得的参数ww在数值上会非常的大，而一般的线性回归其模型是 y=wTxy=wTx ，\n",
    "显然，就是因为ww在数值上非常的大，\n",
    "所以，如果输入变量xx有一个微小的变动，其反应在输出结果上也会变得非常大，\n",
    "这就是对输入变量总的噪声非常敏感的原因。\n",
    "\n",
    "如果能限制参数ww的增长，使ww不会变得特别大，那么模型对输入ww中噪声的敏感度就会降低。\n",
    "这就是脊回归和套索回归（Ridge Regression and Lasso Regrission）的基本思想。\n",
    "\n",
    "===> 所以當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
