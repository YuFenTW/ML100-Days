{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請參考昨天的程式碼，將訓練資料讀取方式改寫成 Generator，並將原本的 model.fit 改為 model.fit_generator 來進行訓練。請參考 Keras [官方文件中 fit_generator 的說明](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os\n",
    "\n",
    "# 防止調用 GPU 報錯：Blas GEMM launch failed\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8 #佔用 GPU 30% 的記憶體資源\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數設定\n",
    "BATCH_SIZE = [256, 512] # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "EPOCHS = [12, 18, 20] # 訓練的 epochs 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x_train, y_train, bs):\n",
    "    while True:\n",
    "        for indexs in range(0, len(x_train), bs):\n",
    "            sub_x_train = x_train[indexs: indexs+bs]\n",
    "            sub_y_train = y_train[indexs: indexs+bs]\n",
    "            yield sub_x_train, sub_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 2.4561 - acc: 0.2214 - val_loss: 1.8617 - val_acc: 0.3213\n",
      "Epoch 2/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.9096 - acc: 0.3118 - val_loss: 1.8085 - val_acc: 0.3504\n",
      "Epoch 3/12\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.8330 - acc: 0.3425 - val_loss: 1.7017 - val_acc: 0.4053\n",
      "Epoch 4/12\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.7764 - acc: 0.3644 - val_loss: 1.6678 - val_acc: 0.4239\n",
      "Epoch 5/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.7363 - acc: 0.3785 - val_loss: 1.6144 - val_acc: 0.4356\n",
      "Epoch 6/12\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.6955 - acc: 0.3936 - val_loss: 1.6931 - val_acc: 0.4103\n",
      "Epoch 7/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.6696 - acc: 0.4034 - val_loss: 1.5788 - val_acc: 0.4361\n",
      "Epoch 8/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.6483 - acc: 0.4102 - val_loss: 1.6013 - val_acc: 0.4334\n",
      "Epoch 9/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.6278 - acc: 0.4195 - val_loss: 1.5487 - val_acc: 0.4514\n",
      "Epoch 10/12\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.6051 - acc: 0.4288 - val_loss: 1.5365 - val_acc: 0.4565\n",
      "Epoch 11/12\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.5872 - acc: 0.4323 - val_loss: 1.5426 - val_acc: 0.4570\n",
      "Epoch 12/12\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.5748 - acc: 0.4358 - val_loss: 1.6375 - val_acc: 0.4231\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 12\n",
      "Test loss: 1.637537959098816\n",
      "Test accuracy: 0.4231\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/18\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.5592 - acc: 0.4417 - val_loss: 1.5810 - val_acc: 0.4455\n",
      "Epoch 2/18\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.5365 - acc: 0.4486 - val_loss: 1.5004 - val_acc: 0.4716\n",
      "Epoch 3/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.5309 - acc: 0.4548 - val_loss: 1.4745 - val_acc: 0.4869\n",
      "Epoch 4/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.5222 - acc: 0.4577 - val_loss: 1.5191 - val_acc: 0.4627\n",
      "Epoch 5/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.5042 - acc: 0.4626 - val_loss: 1.4967 - val_acc: 0.4795\n",
      "Epoch 6/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4995 - acc: 0.4635 - val_loss: 1.4778 - val_acc: 0.4886\n",
      "Epoch 7/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4882 - acc: 0.4687 - val_loss: 1.4544 - val_acc: 0.4879\n",
      "Epoch 8/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4762 - acc: 0.4713 - val_loss: 1.4993 - val_acc: 0.4758\n",
      "Epoch 9/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4657 - acc: 0.4740 - val_loss: 1.4965 - val_acc: 0.4766\n",
      "Epoch 10/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4614 - acc: 0.4763 - val_loss: 1.4781 - val_acc: 0.4767\n",
      "Epoch 11/18\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.4462 - acc: 0.4850 - val_loss: 1.4614 - val_acc: 0.4815\n",
      "Epoch 12/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4468 - acc: 0.4837 - val_loss: 1.5021 - val_acc: 0.4769\n",
      "Epoch 13/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4316 - acc: 0.4889 - val_loss: 1.4445 - val_acc: 0.4933\n",
      "Epoch 14/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4339 - acc: 0.4880 - val_loss: 1.5094 - val_acc: 0.4734\n",
      "Epoch 15/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4279 - acc: 0.4887 - val_loss: 1.4354 - val_acc: 0.4955\n",
      "Epoch 16/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4132 - acc: 0.4964 - val_loss: 1.4422 - val_acc: 0.4886\n",
      "Epoch 17/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4111 - acc: 0.4964 - val_loss: 1.4334 - val_acc: 0.4855\n",
      "Epoch 18/18\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4039 - acc: 0.4982 - val_loss: 1.4125 - val_acc: 0.5084\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 18\n",
      "Test loss: 1.4124697704315186\n",
      "Test accuracy: 0.5084\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.4032 - acc: 0.5000 - val_loss: 1.4976 - val_acc: 0.4713\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.3937 - acc: 0.5028 - val_loss: 1.4125 - val_acc: 0.5060\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3823 - acc: 0.5056 - val_loss: 1.4153 - val_acc: 0.5038\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3841 - acc: 0.5058 - val_loss: 1.4360 - val_acc: 0.4919\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3796 - acc: 0.5083 - val_loss: 1.4287 - val_acc: 0.4986\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 1.3794 - acc: 0.5078 - val_loss: 1.4286 - val_acc: 0.5040\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3687 - acc: 0.5104 - val_loss: 1.4389 - val_acc: 0.4952\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.3618 - acc: 0.5130 - val_loss: 1.4094 - val_acc: 0.5052\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.3577 - acc: 0.5157 - val_loss: 1.3925 - val_acc: 0.5067\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.3552 - acc: 0.5182 - val_loss: 1.4292 - val_acc: 0.4960\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 1.3518 - acc: 0.5141 - val_loss: 1.4245 - val_acc: 0.4952\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.3408 - acc: 0.5224 - val_loss: 1.4562 - val_acc: 0.4907\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 1.3432 - acc: 0.5190 - val_loss: 1.3960 - val_acc: 0.5065\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 1.3416 - acc: 0.5219 - val_loss: 1.4442 - val_acc: 0.4929\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3389 - acc: 0.5265 - val_loss: 1.4263 - val_acc: 0.4884\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.3338 - acc: 0.5233 - val_loss: 1.4021 - val_acc: 0.5076\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 1.3255 - acc: 0.5246 - val_loss: 1.4080 - val_acc: 0.4994\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3221 - acc: 0.5277 - val_loss: 1.4331 - val_acc: 0.5010\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 1.3244 - acc: 0.5256 - val_loss: 1.4088 - val_acc: 0.5037\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 1.3218 - acc: 0.5298 - val_loss: 1.3918 - val_acc: 0.5053\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 20\n",
      "Test loss: 1.3918093858718872\n",
      "Test accuracy: 0.5053\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/12\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2966 - acc: 0.5380 - val_loss: 1.3914 - val_acc: 0.5140\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2935 - acc: 0.5379 - val_loss: 1.4660 - val_acc: 0.4833\n",
      "Epoch 3/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2861 - acc: 0.5389 - val_loss: 1.3780 - val_acc: 0.5116\n",
      "Epoch 4/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2843 - acc: 0.5414 - val_loss: 1.3753 - val_acc: 0.5139\n",
      "Epoch 5/12\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2764 - acc: 0.5447 - val_loss: 1.3864 - val_acc: 0.5105\n",
      "Epoch 6/12\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2756 - acc: 0.5440 - val_loss: 1.3772 - val_acc: 0.5170\n",
      "Epoch 7/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2769 - acc: 0.5432 - val_loss: 1.3662 - val_acc: 0.5142\n",
      "Epoch 8/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2754 - acc: 0.5440 - val_loss: 1.3932 - val_acc: 0.5109\n",
      "Epoch 9/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2656 - acc: 0.5478 - val_loss: 1.4442 - val_acc: 0.5000\n",
      "Epoch 10/12\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2672 - acc: 0.5508 - val_loss: 1.3760 - val_acc: 0.5199\n",
      "Epoch 11/12\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2612 - acc: 0.5494 - val_loss: 1.4017 - val_acc: 0.5080\n",
      "Epoch 12/12\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2535 - acc: 0.5545 - val_loss: 1.3717 - val_acc: 0.5106\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 12\n",
      "Test loss: 1.3716779735565185\n",
      "Test accuracy: 0.5106\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2554 - acc: 0.5501 - val_loss: 1.4182 - val_acc: 0.5039\n",
      "Epoch 2/18\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2588 - acc: 0.5497 - val_loss: 1.3939 - val_acc: 0.5002\n",
      "Epoch 3/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2444 - acc: 0.5559 - val_loss: 1.3672 - val_acc: 0.5181\n",
      "Epoch 4/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2540 - acc: 0.5542 - val_loss: 1.3998 - val_acc: 0.5091\n",
      "Epoch 5/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2390 - acc: 0.5583 - val_loss: 1.3589 - val_acc: 0.5201\n",
      "Epoch 6/18\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2429 - acc: 0.5568 - val_loss: 1.3967 - val_acc: 0.5087\n",
      "Epoch 7/18\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2419 - acc: 0.5558 - val_loss: 1.4016 - val_acc: 0.5032\n",
      "Epoch 8/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2403 - acc: 0.5570 - val_loss: 1.3986 - val_acc: 0.5043\n",
      "Epoch 9/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2333 - acc: 0.5591 - val_loss: 1.3674 - val_acc: 0.5208\n",
      "Epoch 10/18\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2338 - acc: 0.5606 - val_loss: 1.4071 - val_acc: 0.5061\n",
      "Epoch 11/18\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2368 - acc: 0.5590 - val_loss: 1.4358 - val_acc: 0.5048\n",
      "Epoch 12/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2342 - acc: 0.5591 - val_loss: 1.3840 - val_acc: 0.5121\n",
      "Epoch 13/18\n",
      "97/97 [==============================] - ETA: 0s - loss: 1.2215 - acc: 0.564 - 1s 9ms/step - loss: 1.2227 - acc: 0.5643 - val_loss: 1.3950 - val_acc: 0.5155\n",
      "Epoch 14/18\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2245 - acc: 0.5641 - val_loss: 1.4143 - val_acc: 0.5030\n",
      "Epoch 15/18\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2284 - acc: 0.5615 - val_loss: 1.3498 - val_acc: 0.5263\n",
      "Epoch 16/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2224 - acc: 0.5615 - val_loss: 1.3778 - val_acc: 0.5199\n",
      "Epoch 17/18\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2252 - acc: 0.5608 - val_loss: 1.3880 - val_acc: 0.5186\n",
      "Epoch 18/18\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2040 - acc: 0.5702 - val_loss: 1.3832 - val_acc: 0.5151\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 18\n",
      "Test loss: 1.3831900693893433\n",
      "Test accuracy: 0.5151\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2167 - acc: 0.5632 - val_loss: 1.4188 - val_acc: 0.5096\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2181 - acc: 0.5655 - val_loss: 1.4012 - val_acc: 0.5083\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2199 - acc: 0.5652 - val_loss: 1.3720 - val_acc: 0.5178\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2130 - acc: 0.5653 - val_loss: 1.4211 - val_acc: 0.5021\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2100 - acc: 0.5673 - val_loss: 1.3684 - val_acc: 0.5216\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2083 - acc: 0.5688 - val_loss: 1.3858 - val_acc: 0.5205\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2066 - acc: 0.5690 - val_loss: 1.3948 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2013 - acc: 0.5732 - val_loss: 1.3954 - val_acc: 0.5036\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.2009 - acc: 0.5714 - val_loss: 1.3806 - val_acc: 0.5172\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1980 - acc: 0.5704 - val_loss: 1.3700 - val_acc: 0.5219\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1973 - acc: 0.5731 - val_loss: 1.3804 - val_acc: 0.5146\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2046 - acc: 0.5701 - val_loss: 1.3685 - val_acc: 0.5221\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.1973 - acc: 0.5717 - val_loss: 1.3533 - val_acc: 0.5233\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.1943 - acc: 0.5732 - val_loss: 1.3846 - val_acc: 0.5138\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1986 - acc: 0.5715 - val_loss: 1.4026 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1846 - acc: 0.5758 - val_loss: 1.3864 - val_acc: 0.5167\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1889 - acc: 0.5759 - val_loss: 1.4157 - val_acc: 0.5069\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1907 - acc: 0.5742 - val_loss: 1.4086 - val_acc: 0.5084\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1796 - acc: 0.5764 - val_loss: 1.4209 - val_acc: 0.4996\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1857 - acc: 0.5761 - val_loss: 1.4093 - val_acc: 0.5057\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 20\n",
      "Test loss: 1.4092900463104248\n",
      "Test accuracy: 0.5057\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for bs in BATCH_SIZE:\n",
    "    for ep in EPOCHS:\n",
    "        history = model.fit_generator(generate_batch_data(x_train, y_train, bs),\n",
    "                                      steps_per_epoch=len(y_train)//bs,\n",
    "                                      epochs=ep,\n",
    "                                      verbose=1,\n",
    "                                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('--------------------------------------------------\\nbs = ',bs,', ep=',ep)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "195/195 [==============================] - 10s 51ms/step - loss: 1.8851 - acc: 0.3151 - val_loss: 1.6032 - val_acc: 0.4286\n",
      "Epoch 2/12\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 1.4822 - acc: 0.4714 - val_loss: 1.2333 - val_acc: 0.5630 - los - ETA: 1s - loss: 1.5\n",
      "Epoch 3/12\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 1.2779 - acc: 0.5474 - val_loss: 1.1016 - val_acc: 0.6137\n",
      "Epoch 4/12\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 1.1329 - acc: 0.6036 - val_loss: 0.9871 - val_acc: 0.6507\n",
      "Epoch 5/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 1.0221 - acc: 0.6429 - val_loss: 0.9590 - val_acc: 0.6612\n",
      "Epoch 6/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.9389 - acc: 0.6725 - val_loss: 0.9492 - val_acc: 0.6828\n",
      "Epoch 7/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.8708 - acc: 0.6982 - val_loss: 0.8335 - val_acc: 0.7055\n",
      "Epoch 8/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.8082 - acc: 0.7180 - val_loss: 0.9217 - val_acc: 0.6940\n",
      "Epoch 9/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.7659 - acc: 0.7336 - val_loss: 0.8563 - val_acc: 0.7015\n",
      "Epoch 10/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.7235 - acc: 0.7494 - val_loss: 0.7384 - val_acc: 0.7479\n",
      "Epoch 11/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.6824 - acc: 0.7617 - val_loss: 0.7255 - val_acc: 0.7492\n",
      "Epoch 12/12\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.6527 - acc: 0.7721 - val_loss: 0.6915 - val_acc: 0.7623\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 12\n",
      "Test loss: 0.6915247264862061\n",
      "Test accuracy: 0.7623\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/18\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.6175 - acc: 0.7849 - val_loss: 0.7317 - val_acc: 0.7503\n",
      "Epoch 2/18\n",
      "195/195 [==============================] - 7s 36ms/step - loss: 0.5958 - acc: 0.7916 - val_loss: 0.7273 - val_acc: 0.7568\n",
      "Epoch 3/18\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.5705 - acc: 0.7990 - val_loss: 0.6875 - val_acc: 0.7699\n",
      "Epoch 4/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.5535 - acc: 0.8069 - val_loss: 0.6870 - val_acc: 0.7740\n",
      "Epoch 5/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.5303 - acc: 0.8165 - val_loss: 0.6775 - val_acc: 0.7719\n",
      "Epoch 6/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.5170 - acc: 0.8194 - val_loss: 0.6664 - val_acc: 0.7851\n",
      "Epoch 7/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4994 - acc: 0.8248 - val_loss: 0.6648 - val_acc: 0.7870\n",
      "Epoch 8/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4916 - acc: 0.8319 - val_loss: 0.6701 - val_acc: 0.7750\n",
      "Epoch 9/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4758 - acc: 0.8362 - val_loss: 0.6488 - val_acc: 0.7823 a - ETA: 0s - loss: 0.4751 - acc: 0.83\n",
      "Epoch 10/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4714 - acc: 0.8371 - val_loss: 0.6662 - val_acc: 0.7842\n",
      "Epoch 11/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4549 - acc: 0.8429 - val_loss: 0.6957 - val_acc: 0.7912oss: 0.4544 - acc: \n",
      "Epoch 12/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4587 - acc: 0.8414 - val_loss: 0.7245 - val_acc: 0.76244588 - acc: \n",
      "Epoch 13/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4536 - acc: 0.8436 - val_loss: 0.7019 - val_acc: 0.7845\n",
      "Epoch 14/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4452 - acc: 0.8467 - val_loss: 0.7341 - val_acc: 0.7942s: 0.4438 -\n",
      "Epoch 15/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4435 - acc: 0.8482 - val_loss: 0.6136 - val_acc: 0.7925\n",
      "Epoch 16/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4352 - acc: 0.8520 - val_loss: 0.6652 - val_acc: 0.7918\n",
      "Epoch 17/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4362 - acc: 0.8503 - val_loss: 0.6841 - val_acc: 0.7931\n",
      "Epoch 18/18\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4300 - acc: 0.8538 - val_loss: 0.8134 - val_acc: 0.7753\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 18\n",
      "Test loss: 0.8134244260787964\n",
      "Test accuracy: 0.7753\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4288 - acc: 0.8547 - val_loss: 0.7497 - val_acc: 0.7923\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4210 - acc: 0.8582 - val_loss: 0.8648 - val_acc: 0.7877\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4198 - acc: 0.8578 - val_loss: 0.6701 - val_acc: 0.7961\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4220 - acc: 0.8599 - val_loss: 0.7431 - val_acc: 0.7915\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4232 - acc: 0.8577 - val_loss: 0.7491 - val_acc: 0.8004\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4249 - acc: 0.8566 - val_loss: 0.7444 - val_acc: 0.7975 - loss: 0.4231 - acc:  - ETA: 1s - loss: 0.4\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4184 - acc: 0.8606 - val_loss: 0.7030 - val_acc: 0.7954\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.4163 - acc: 0.8629 - val_loss: 0.7482 - val_acc: 0.7918\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 6s 33ms/step - loss: 0.4134 - acc: 0.8637 - val_loss: 0.7233 - val_acc: 0.7750\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4145 - acc: 0.8619 - val_loss: 0.8183 - val_acc: 0.7880\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4147 - acc: 0.8613 - val_loss: 0.8937 - val_acc: 0.7966\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 7s 36ms/step - loss: 0.4195 - acc: 0.8617 - val_loss: 0.6970 - val_acc: 0.7894\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 0.4165 - acc: 0.8645 - val_loss: 0.7921 - val_acc: 0.7989\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 7s 33ms/step - loss: 0.4135 - acc: 0.8628 - val_loss: 0.6427 - val_acc: 0.7949\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.4122 - acc: 0.8642 - val_loss: 0.6222 - val_acc: 0.8034\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4017 - acc: 0.8672 - val_loss: 0.7371 - val_acc: 0.8004\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.4135 - acc: 0.8663 - val_loss: 0.7262 - val_acc: 0.7655\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4162 - acc: 0.8656 - val_loss: 0.7391 - val_acc: 0.7932\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4143 - acc: 0.8679 - val_loss: 0.7729 - val_acc: 0.7986\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 0.4116 - acc: 0.8658 - val_loss: 0.7601 - val_acc: 0.8016\n",
      "--------------------------------------------------\n",
      "bs =  256 , ep= 20\n",
      "Test loss: 0.7600789571285248\n",
      "Test accuracy: 0.8016\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/12\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 0.3885 - acc: 0.8748 - val_loss: 0.7328 - val_acc: 0.8028\n",
      "Epoch 2/12\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.3805 - acc: 0.8772 - val_loss: 0.6200 - val_acc: 0.8014\n",
      "Epoch 3/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3691 - acc: 0.8807 - val_loss: 0.7847 - val_acc: 0.8010\n",
      "Epoch 4/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3590 - acc: 0.8816 - val_loss: 0.6725 - val_acc: 0.8092\n",
      "Epoch 5/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3530 - acc: 0.8851 - val_loss: 0.8471 - val_acc: 0.8026\n",
      "Epoch 6/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3601 - acc: 0.8838 - val_loss: 0.9041 - val_acc: 0.8086\n",
      "Epoch 7/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3464 - acc: 0.8883 - val_loss: 0.7208 - val_acc: 0.8064\n",
      "Epoch 8/12\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3411 - acc: 0.8888 - val_loss: 0.6599 - val_acc: 0.8045\n",
      "Epoch 9/12\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 0.3295 - acc: 0.8922 - val_loss: 0.7807 - val_acc: 0.8076\n",
      "Epoch 10/12\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 0.3440 - acc: 0.8889 - val_loss: 0.9114 - val_acc: 0.8068\n",
      "Epoch 11/12\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 0.3333 - acc: 0.8912 - val_loss: 0.7461 - val_acc: 0.8008\n",
      "Epoch 12/12\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.3337 - acc: 0.8915 - val_loss: 0.6691 - val_acc: 0.8058\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 12\n",
      "Test loss: 0.6691177461624146\n",
      "Test accuracy: 0.8058\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/18\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.3329 - acc: 0.8917 - val_loss: 0.6519 - val_acc: 0.7938\n",
      "Epoch 2/18\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3236 - acc: 0.8958 - val_loss: 0.8256 - val_acc: 0.7949\n",
      "Epoch 3/18\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.3267 - acc: 0.8944 - val_loss: 0.6973 - val_acc: 0.7978\n",
      "Epoch 4/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3173 - acc: 0.8943 - val_loss: 0.6819 - val_acc: 0.7974\n",
      "Epoch 5/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3183 - acc: 0.8968 - val_loss: 0.7311 - val_acc: 0.8032\n",
      "Epoch 6/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3145 - acc: 0.8976 - val_loss: 0.7029 - val_acc: 0.8007\n",
      "Epoch 7/18\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.3182 - acc: 0.8978 - val_loss: 0.7033 - val_acc: 0.8043\n",
      "Epoch 8/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3108 - acc: 0.8987 - val_loss: 0.7522 - val_acc: 0.8109\n",
      "Epoch 9/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3173 - acc: 0.8981 - val_loss: 0.8354 - val_acc: 0.8123\n",
      "Epoch 10/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3066 - acc: 0.9002 - val_loss: 0.6811 - val_acc: 0.8094\n",
      "Epoch 11/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3115 - acc: 0.8982 - val_loss: 0.7323 - val_acc: 0.7907\n",
      "Epoch 12/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3085 - acc: 0.9012 - val_loss: 0.8165 - val_acc: 0.8057\n",
      "Epoch 13/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3055 - acc: 0.9016 - val_loss: 0.7092 - val_acc: 0.8094\n",
      "Epoch 14/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2951 - acc: 0.9044 - val_loss: 0.7121 - val_acc: 0.8053\n",
      "Epoch 15/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3005 - acc: 0.9038 - val_loss: 0.7334 - val_acc: 0.8015\n",
      "Epoch 16/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3035 - acc: 0.9014 - val_loss: 0.7432 - val_acc: 0.8003\n",
      "Epoch 17/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.3036 - acc: 0.9029 - val_loss: 0.7714 - val_acc: 0.8061\n",
      "Epoch 18/18\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2939 - acc: 0.9059 - val_loss: 0.7635 - val_acc: 0.8049\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 18\n",
      "Test loss: 0.7634691834867\n",
      "Test accuracy: 0.8049\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.2972 - acc: 0.9041 - val_loss: 0.7362 - val_acc: 0.7900\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2927 - acc: 0.9049 - val_loss: 0.7321 - val_acc: 0.8143\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.2973 - acc: 0.9044 - val_loss: 0.9002 - val_acc: 0.8109\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.2972 - acc: 0.9058 - val_loss: 0.7202 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.2971 - acc: 0.9042 - val_loss: 0.9490 - val_acc: 0.8106\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.2992 - acc: 0.9035 - val_loss: 0.6948 - val_acc: 0.7991\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.2879 - acc: 0.9091 - val_loss: 0.6718 - val_acc: 0.7962\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2870 - acc: 0.9085 - val_loss: 0.7033 - val_acc: 0.8075\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2843 - acc: 0.9084 - val_loss: 0.7647 - val_acc: 0.8006\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2870 - acc: 0.9087 - val_loss: 0.7890 - val_acc: 0.7990\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2903 - acc: 0.9073 - val_loss: 0.7154 - val_acc: 0.8023\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2888 - acc: 0.9088 - val_loss: 0.8749 - val_acc: 0.8108\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2888 - acc: 0.9081 - val_loss: 0.7352 - val_acc: 0.7972\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2812 - acc: 0.9095 - val_loss: 0.7373 - val_acc: 0.7978\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2824 - acc: 0.9104 - val_loss: 0.7068 - val_acc: 0.7853\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2854 - acc: 0.9076 - val_loss: 0.8564 - val_acc: 0.8105\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2875 - acc: 0.9082 - val_loss: 0.9470 - val_acc: 0.8066\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 62ms/step - loss: 0.2811 - acc: 0.9105 - val_loss: 0.6895 - val_acc: 0.8034\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 0.2833 - acc: 0.9099 - val_loss: 0.9979 - val_acc: 0.8059\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 0.2785 - acc: 0.9109 - val_loss: 0.8040 - val_acc: 0.8114\n",
      "--------------------------------------------------\n",
      "bs =  512 , ep= 20\n",
      "Test loss: 0.8039754345655441\n",
      "Test accuracy: 0.8114\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for bs in BATCH_SIZE:\n",
    "    for ep in EPOCHS:\n",
    "        history = model.fit_generator(generate_batch_data(x_train, y_train, bs),\n",
    "                                      steps_per_epoch=len(y_train)//bs,\n",
    "                                      epochs=ep,\n",
    "                                      verbose=1,\n",
    "                                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('--------------------------------------------------\\nbs = ',bs,', ep=',ep)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
